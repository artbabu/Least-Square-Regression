{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'print', 'invalid': 'print', 'over': 'print', 'under': 'print'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.special as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations, permutations\n",
    "from numpy.linalg import inv\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import time\n",
    "import keras\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "np.seterr(all='print')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_feature_List = ['country_group_CAN','country_group_EURO', 'country_group_USA', 'Position_C',\n",
    "       'Position_D', 'Position_L', 'Position_R'] \n",
    "def standardize(s_df):\n",
    "    for col in s_df.columns.values:\n",
    "        col_mean = s_df[col].mean()\n",
    "        col_std = s_df[col].std()\n",
    "\n",
    "        #         mean of interaction terms of two discrete variable are zero. those columns are\n",
    "        #         filtered while standizing as it cause singular matrix\n",
    "        if (col_mean != 0 or col_std != 0) or col not in dummy_feature_List :\n",
    "            s_df[col] = s_df[col].apply(lambda x: (x - col_mean) / float(col_std))\n",
    "\n",
    "    return s_df\n",
    "\n",
    "\n",
    "def preprocessing(x_df):\n",
    "    x_df = pd.get_dummies(x_df, prefix=['country_group', 'Position'], columns=['country_group', 'Position'])\n",
    "    x_df = x_df.apply(pd.to_numeric, args=('coerce',))\n",
    "\n",
    "#     # # adding interaction terms\n",
    "#     for col_1, col_2 in combinations(x_df.columns, 2):\n",
    "#         cond1 = col_1 not in dummy_feature_List\n",
    "#         cond2 = col_2 not in dummy_feature_List\n",
    "#         if cond1 or cond2:\n",
    "#             x_df['{}*{}'.format(col_1, col_2)] = np.multiply(x_df[col_1], x_df[col_2])\n",
    "#     # x_df.to_csv('ex.csv', sep='\\t')\n",
    "\n",
    "# #     standardization\n",
    "#     x_df = standardize(x_df)\n",
    "# #     y_df = standardize(y_df)\n",
    "\n",
    "    #     deleteing column = 0\n",
    "    x_df = x_df.loc[:, (x_df != 0).any(axis=0)]\n",
    "#     x_df.insert(loc=0, column='x0', value=1)\n",
    "\n",
    "    return x_df\n",
    "\n",
    "def calculate_negative_log_likelihood(target, weights, features):\n",
    "    \n",
    "    z = np.dot(weights,features)\n",
    "    y = sps.expit(z)\n",
    "    mask = np.isinf(y)\n",
    "    y[mask] = -z[mask]\n",
    "    \n",
    "    likelihood = np.mean(np.sum((1-target)*z + np.log(y)))\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    input = os.path.join(\"../MLAssign2/Least-Square-Regression/\",'Model_Trees_Full_Dataset', 'preprocessed_datasets.csv')\n",
    "    data = pd.read_csv(input)\n",
    "\n",
    "    # random shuffle\n",
    "    data = data.iloc[np.random.permutation(len(data))]\n",
    "    # data[u'GP_greater_than_0'] = data[u'GP_greater_than_0'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "    training_df = data[data[u'DraftYear'].isin([2004, 2005, 2006])]\n",
    "    testing_df = data[data[u'DraftYear'] == 2007]\n",
    "\n",
    "    drop_class = [u'id', u'Country', u'Overall', u'PlayerName', u'sum_7yr_TOI', u'DraftYear',\"GP_greater_than_0\"]\n",
    "    training_df.drop(drop_class, inplace=True, axis=1)\n",
    "    testing_df.drop(drop_class, inplace=True, axis=1)\n",
    "\n",
    "    y_train_df = training_df.filter([u'sum_7yr_GP'])\n",
    "    x_train_df = training_df.drop([u'sum_7yr_GP'], axis=1)\n",
    "\n",
    "    y_test_df = testing_df.filter([u'sum_7yr_GP'])\n",
    "    x_test_df = testing_df.drop([u'sum_7yr_GP'], axis=1)\n",
    "\n",
    "    x_train_df_processed = preprocessing(x_train_df)\n",
    "    x_test_df_processed = preprocessing(x_test_df)\n",
    "\n",
    "    y_train = y_train_df.values\n",
    "    x_train = x_train_df_processed.values\n",
    "    y_test = y_test_df.values\n",
    "    x_test = x_test_df_processed.values\n",
    "    \n",
    "    return (x_train,y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aarthy/anaconda3/envs/NLP/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/aarthy/anaconda3/envs/NLP/lib/python2.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tol = 0.00001\n",
    "\n",
    "# Step size for gradient descent.\n",
    "etas = [0.5, 0.3, 0.1, 0.05, 0.01]\n",
    "# etas = [0.1, 0.05, 0.01]\n",
    "\n",
    "(x_train,y_train), (x_test, y_test) = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20,  73, 205, ...,   1,   0,   0],\n",
       "       [ 19,  74, 201, ...,   0,   1,   0],\n",
       "       [ 18,  71, 194, ...,   0,   0,   0],\n",
       "       ..., \n",
       "       [ 20,  73, 207, ...,   0,   0,   0],\n",
       "       [ 19,  71, 183, ...,   0,   0,   0],\n",
       "       [ 19,  75, 203, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637, 22)\n",
      "(637, 1)\n",
      "(191, 22)\n",
      "(191, 1)\n"
     ]
    }
   ],
   "source": [
    "print x_train.shape\n",
    "print y_train.shape\n",
    "print x_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compield in 0.0866219997406 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200, input_dim=22, activation='relu' ))\n",
    "model.add(Dense(units=100, activation='relu' ))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "# model.compile(loss=\"mean_squared_error\", optimizer ='adam', metrics=['accuracy'])\n",
    "\n",
    "# rms = RMSprop()\n",
    "sgd = keras.optimizers.SGD(lr=1)\n",
    "model.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['accuracy'])\n",
    "print 'Model compield in {0} seconds'.format(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 2/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 3/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 4/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 5/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 6/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 7/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 8/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 9/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n",
      "Epoch 10/10\n",
      "637/637 [==============================] - 0s - loss: 64.3642 - acc: 0.5573     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f011a14fc50>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
    "# model.fit(x_test, y_test, epochs=150,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating on testing set...\n",
      "128/191 [===================>..........] - ETA: 0s[INFO] loss=63.7644, accuracy: 52.8796%\n"
     ]
    }
   ],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating on testing set...\")\n",
    "(loss, accuracy) = model.evaluate(x_test, y_test,\n",
    "\tbatch_size=128, verbose=1)\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,\n",
    "\taccuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9]\n",
      " [  0]\n",
      " [203]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [415]\n",
      " [136]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [515]\n",
      " [324]\n",
      " [189]\n",
      " [  1]\n",
      " [  0]\n",
      " [282]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 35]\n",
      " [  0]\n",
      " [108]\n",
      " [  0]\n",
      " [  1]\n",
      " [ 18]\n",
      " [ 25]\n",
      " [  0]\n",
      " [203]\n",
      " [  0]\n",
      " [124]\n",
      " [  0]\n",
      " [ 87]\n",
      " [297]\n",
      " [ 11]\n",
      " [  0]\n",
      " [ 25]\n",
      " [136]\n",
      " [  0]\n",
      " [  0]\n",
      " [246]\n",
      " [  3]\n",
      " [ 79]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [449]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 58]\n",
      " [  0]\n",
      " [ 10]\n",
      " [ 13]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 87]\n",
      " [132]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [176]\n",
      " [ 29]\n",
      " [  0]\n",
      " [ 63]\n",
      " [ 75]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [119]\n",
      " [  0]\n",
      " [  0]\n",
      " [157]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 81]\n",
      " [283]\n",
      " [ 67]\n",
      " [ 61]\n",
      " [154]\n",
      " [  0]\n",
      " [481]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  7]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 72]\n",
      " [102]\n",
      " [110]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  1]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  5]\n",
      " [316]\n",
      " [  0]\n",
      " [  2]\n",
      " [ 54]\n",
      " [  0]\n",
      " [297]\n",
      " [217]\n",
      " [164]\n",
      " [284]\n",
      " [246]\n",
      " [ 28]\n",
      " [344]\n",
      " [ 40]\n",
      " [  0]\n",
      " [319]\n",
      " [286]\n",
      " [ 72]\n",
      " [ 16]\n",
      " [113]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 55]\n",
      " [  0]\n",
      " [106]\n",
      " [  0]\n",
      " [132]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 25]\n",
      " [  0]\n",
      " [  0]\n",
      " [304]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 10]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 68]\n",
      " [345]\n",
      " [ 12]\n",
      " [  0]\n",
      " [ 22]\n",
      " [ 58]\n",
      " [  0]\n",
      " [120]\n",
      " [  0]\n",
      " [ 10]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [211]\n",
      " [  3]\n",
      " [  0]\n",
      " [418]\n",
      " [  0]\n",
      " [449]\n",
      " [  0]\n",
      " [ 22]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 20]\n",
      " [  0]\n",
      " [ 77]\n",
      " [121]\n",
      " [126]\n",
      " [129]\n",
      " [184]\n",
      " [  0]\n",
      " [ 87]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [  3]\n",
      " [  0]]\n"
     ]
    }
   ],
   "source": [
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
